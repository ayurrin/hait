{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基本的にstacking.ipynbとほとんど同じだが、learn_modelの定義のみ異なる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#必要なものをインストール\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier, \n",
    "                              GradientBoostingClassifier, ExtraTreesClassifier)\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データセットをつくる\n",
    "ホールドアウト法で大体の結果を確かめるためのテスト用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=pd.read_csv(\"df_yy_all_log2.csv\")#ここに入れるデータ名を入れ替えていろいろな例を試す\n",
    "X = df_test.drop('y',axis=1).values\n",
    "y=df_test.loc[:,[\"y\"]].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "y_train= y_train.reshape(-1)\n",
    "y_test= y_test.reshape(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データセット　本番用\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"df_yy_all_log2.csv\")\n",
    "df_t=pd.read_csv('df_yy_all_log_test.csv')\n",
    "X_train= df.drop('y',axis=1).values\n",
    "y_train=df.loc[:,[\"y\"]].values\n",
    "X_test=df_t.values\n",
    "y_train= y_train.reshape(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習モデルの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc=RandomForestClassifier(random_state=0, n_estimators=1000,max_depth= 15,\n",
    "#                            class_weight=\"balanced\"　:うまくy＝1が予測されるようにしようとするときに試した\n",
    "                          )\n",
    "gbct = GradientBoostingClassifier(n_estimators=5000,random_state=0, max_depth=15, learning_rate=0.01)\n",
    "ada=AdaBoostClassifier(n_estimators=500, learning_rate=0.01, random_state=0)\n",
    "ext=ExtraTreesClassifier(n_estimators=10000, max_depth =6)\n",
    "rbf_svm = SVC(kernel='rbf', gamma=0.1, C=1,probability=True)\n",
    "lgb = lgb.LGBMClassifier(num_leaves = 30,learning_rate=0.1,min_child_samples=20,n_estimators=2000,\n",
    "#                          class_weight=\"balanced\" :うまくy＝1が予測されるようにしようとするときに試した\n",
    "                        )\n",
    "xgb = xgb.XGBClassifier(learning_rate = 0.02,n_estimators= 2000,max_depth= 15,min_child_weight= 1, gamma=0.9,\n",
    "#                         class_weight=\"balanced\"\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K個に分割してtrainデータの予測値を求める"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "オーバーサンプリング用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_model(model):\n",
    "#yのクラスの比率が等しくなるようにホールドする\n",
    "#     kf = KFold(n_splits=5, random_state=0, shuffle=True) :通常の分割方法\n",
    "# 分けたときのyのバランスが良くなるようにしたもの    \n",
    "    kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "    ntrain=X_train.shape[0]\n",
    "    ntest=X_test.shape[0]\n",
    "#結果を記録していくためのものをつくる   \n",
    "    mo_train=np.zeros((ntrain,))\n",
    "    mo_test = np.zeros((ntest,))\n",
    "    mo_test_m = np.empty((5, ntest))\n",
    "    mo_train_pro=np.zeros((ntrain,))\n",
    "    mo_test_pro = np.zeros((ntest,))\n",
    "    mo_test_m_pro = np.empty((5, ntest))\n",
    "    \n",
    "    for i, (train_index, test_index) in enumerate(kf.split(X_train,y_train)):\n",
    "    #分けたデータの1つは予測するためのテストデータとして扱い、残りのデータを使って学習する\n",
    "        X_train1, X_test_1 = X_train[train_index], X_train[test_index]\n",
    "        y_train1, y_test_1 = y_train[train_index], y_train[test_index]\n",
    "        a=len(y_train1[y_train1==0])\n",
    "\n",
    "        # ランダムにover-sampling\n",
    "        ros = RandomOverSampler(ratio={0: a, 1: a//2}, random_state=0)\n",
    "        X_train_1, y_train_1 = ros.fit_sample(X_train1, y_train1)\n",
    "\n",
    "        model.fit(X_train_1,y_train_1)\n",
    "        print('train accuracy: %.3f' % model.score(X_train_1, y_train_1))\n",
    "        print('test accuracy: %.3f' % model.score(X_test_1, y_test_1))\n",
    "        \n",
    "        print(metrics.accuracy_score(y_test_1, model.predict(X_test_1)))\n",
    "        # 再現率を出力\n",
    "        print(metrics.recall_score(y_test_1, model.predict(X_test_1)))\n",
    "        # 適合率を出力\n",
    "        print(metrics.precision_score(y_test_1, model.predict(X_test_1)))\n",
    "        # F値を出力\n",
    "        print(metrics.f1_score(y_test_1, model.predict(X_test_1)))\n",
    "        \n",
    "        mo_train[test_index] =model.predict(X_test_1)\n",
    "        mo_test_m[i, :] = model.predict(X_test)\n",
    "        mo_train_pro[test_index] =model.predict_proba(X_test_1)[:,1]\n",
    "        mo_test_m_pro[i, :] = model.predict_proba(X_test)[:,1]\n",
    "    mo_test[:]=mo_test_m.mean(axis=0)\n",
    "    mo_test_pro[:]=mo_test_m_pro.mean(axis=0)\n",
    "   \n",
    "    return mo_train.reshape(-1, 1), mo_test.reshape(-1, 1),mo_train_pro.reshape(-1, 1), mo_test_pro.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "アンダーサンプリング用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn_model(model):\n",
    "#yのクラスの比率が等しくなるようにホールドする\n",
    "#     kf = KFold(n_splits=5, random_state=0, shuffle=True) :通常の分割方法\n",
    "# 分けたときのyのバランスが良くなるようにしたもの    \n",
    "    kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "    ntrain=X_train.shape[0]\n",
    "    ntest=X_test.shape[0]\n",
    "#結果を記録していくためのものをつくる   \n",
    "    mo_train=np.zeros((ntrain,))\n",
    "    mo_test = np.zeros((ntest,))\n",
    "    mo_test_m = np.empty((5, ntest))\n",
    "    mo_train_pro=np.zeros((ntrain,))\n",
    "    mo_test_pro = np.zeros((ntest,))\n",
    "    mo_test_m_pro = np.empty((5, ntest))\n",
    "    \n",
    "    for i, (train_index, test_index) in enumerate(kf.split(X_train,y_train)):\n",
    "    #分けたデータの1つは予測するためのテストデータとして扱い、残りのデータを使って学習する\n",
    "        X_train1, X_test_1 = X_train[train_index], X_train[test_index]\n",
    "        y_train1, y_test_1 = y_train[train_index], y_train[test_index]\n",
    "        # y＝1のサンプル数をカウント\n",
    "        positive_count_train = y_train1.sum()\n",
    "        print('positive count: {}'.format(positive_count_train))\n",
    "        \n",
    "\n",
    "        # ランダムにunder-sampling\n",
    "        rus = RandomUnderSampler(ratio={0:positive_count_train*4, 1:positive_count_train}, random_state=0)\n",
    "        X_train_1, y_train_1 = rus.fit_sample(X_train1, y_train1)\n",
    "\n",
    "        model.fit(X_train_1,y_train_1)\n",
    "        print('train accuracy: %.3f' % model.score(X_train_1, y_train_1))\n",
    "        print('test accuracy: %.3f' % model.score(X_test_1, y_test_1))\n",
    "        \n",
    "        print(metrics.accuracy_score(y_test_1, model.predict(X_test_1)))\n",
    "        # 再現率を出力\n",
    "        print(metrics.recall_score(y_test_1, model.predict(X_test_1)))\n",
    "        # 適合率を出力\n",
    "        print(metrics.precision_score(y_test_1, model.predict(X_test_1)))\n",
    "        # F値を出力\n",
    "        print(metrics.f1_score(y_test_1, model.predict(X_test_1)))\n",
    "        \n",
    "        mo_train[test_index] =model.predict(X_test_1)\n",
    "        mo_test_m[i, :] = model.predict(X_test)\n",
    "        mo_train_pro[test_index] =model.predict_proba(X_test_1)[:,1]\n",
    "        mo_test_m_pro[i, :] = model.predict_proba(X_test)[:,1]\n",
    "    mo_test[:]=mo_test_m.mean(axis=0)\n",
    "    mo_test_pro[:]=mo_test_m_pro.mean(axis=0)\n",
    "    # print(mo_test.reshape(-1,1))\n",
    "    return mo_train.reshape(-1, 1), mo_test.reshape(-1, 1),mo_train_pro.reshape(-1, 1), mo_test_pro.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学習させるモデルを順番に学習して、train,testの結果を受け取る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gridsearchにより最適なパラメータを求める（RandomForest）\n",
    "\n",
    "# params = {'n_estimators'  : [ 10, 100, 1000, 10000] }\n",
    "# kf_1 = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "# gs_rf = GridSearchCV(RandomForestClassifier(), params, cv = kf_1)\n",
    "# gs_rf.fit(X_train, y_train)\n",
    "# print(gs_rf.score(X_train,y_train))\n",
    "# print(gs_rf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomForestの学習\n",
    "print(\"rfc\")\n",
    "rfc_train,rfc_test,rfc_train_pro,rfc_test_pro=learn_model(rfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gridsearch:GrasientBoost\n",
    "\n",
    "# params = {'n_estimators'  : [ 5000,8000], \n",
    "#          'learning_rate' :[0.01,0.005]}\n",
    "# gs_gb = GridSearchCV(GradientBoostingClassifier(), params, cv = kf_1)\n",
    "# gs_gb.fit(X_train, y_train)\n",
    "# print(gs_gb.score(X_train,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(gs_gb.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GrasientBoostの学習\n",
    "print(\"gbct\")\n",
    "gbct_train,gbct_test,gbct_train_pro,gbct_test_pro=learn_model(gbct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gridsearch:\n",
    "\n",
    "# params = {'n_estimators'  : [ 10, 100, 1000, 10000], \n",
    "#          'learning_rate' :[0.01,,1.0]}\n",
    "# gs_ad = GridSearchCV(AdaBoostClassifier(), params, cv = kf_1)\n",
    "# gs_ad.fit(X_train, y_train)\n",
    "# print(gs_ad.score(X_train,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AdaBoostの学習\n",
    "print(\"ad\")\n",
    "ada_train, ada_test,ada_train_pro, ada_test_pro=learn_model(ada)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grisserch: ExtraTreesClassifier\n",
    "\n",
    "# params = {'n_estimators'  : [10, 100, 1000, 10000], \n",
    "#          }\n",
    "# gs_ex = GridSearchCV(ExtraTreesClassifier(), params, cv = kf_1)\n",
    "# gs_ex.fit(X_train, y_train)\n",
    "# print(gs_ex.score(X_train,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ExtraTreesClassifierの学習\n",
    "print(\"ext\")\n",
    "ext_train, ext_test,ext_train_pro, ext_test_pro=learn_model(ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#GridSearch :SVC\n",
    "\n",
    "# param_grid = {'C': [0.1, 1.0, 10],\n",
    "#  'gamma': [0.001, 0.01]}\n",
    "# gs_svc = GridSearchCV(SVC(), param_grid, cv=kf_1)\n",
    "# gs_svc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gs_svc.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVCの学習（精度が悪く、学習時間が長いため使用しない）\n",
    "# print(\"svc\")\n",
    "# svm_train, svm_test,svm_train_pro, svm_test_pro=learn_model(rbf_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lightGBMの学習\n",
    "print(\"lgb\")\n",
    "lgb_train, lgb_test,lgb_train_pro, lgb_test_pro=learn_model(lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoostの学習\n",
    "print(\"xgb\")\n",
    "xgb_train, xgb_test,xgb_train_pro, xgb_test_pro=learn_model(xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ロジスティック回帰追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "#標準化\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_std_ba = scaler.transform(X_train)\n",
    "X_std_test=scaler.transform(X_test)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(C=1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#引数にtrainデータとtestデータを指定する以外上のモデルと一緒（標準化処理を加えたから）\n",
    "def learn_log(model,X_train,X_test):\n",
    "    kf =StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "    ntrain=X_train.shape[0]\n",
    "    ntest=X_test.shape[0]\n",
    "    mo_train=np.zeros((ntrain,))\n",
    "    mo_test = np.zeros((ntest,))\n",
    "    mo_test_m = np.empty((5, ntest))\n",
    "    mo_train_pro=np.zeros((ntrain,))\n",
    "    mo_test_pro = np.zeros((ntest,))\n",
    "    mo_test_m_pro = np.empty((5, ntest))\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(X_train,y_train)):\n",
    "        X_train_1, X_test_1 = X_train[train_index], X_train[test_index]\n",
    "        y_train_1, y_test_1 = y_train[train_index], y_train[test_index]\n",
    "\n",
    "        model.fit(X_train_1,y_train_1)\n",
    "        print('train accuracy: %.3f' % model.score(X_train_1, y_train_1))\n",
    "        print('test accuracy: %.3f' % model.score(X_test_1, y_test_1))\n",
    "        # 再現率を出力\n",
    "        print(metrics.recall_score(y_test_1, model.predict(X_test_1)))\n",
    "        # 適合率を出力\n",
    "        print(metrics.precision_score(y_test_1, model.predict(X_test_1)))\n",
    "        # F値を出力\n",
    "        print(metrics.f1_score(y_test_1, model.predict(X_test_1)))\n",
    "\n",
    "        mo_train[test_index] =model.predict(X_test_1)\n",
    "        mo_test_m_pro[i, :] = model.predict(X_test)\n",
    "        mo_train_pro[test_index] =model.predict_proba(X_test_1)[:,1]\n",
    "        mo_test_m_pro[i, :] = model.predict_proba(X_test)[:,1]\n",
    "    mo_test[:]=mo_test_m.mean(axis=0)\n",
    "    mo_test_pro[:]=mo_test_m_pro.mean(axis=0)\n",
    "    # print(mo_test.reshape(-1,1))\n",
    "    return mo_train.reshape(-1, 1), mo_test.reshape(-1, 1),mo_train_pro.reshape(-1, 1), mo_test_pro.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_train, log_test, log_train_pro, log_test_pro=learn_log(lr,X_std_ba,X_std_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1回目の学習を行ったデータが消えてしまうとまた実行し直すのが大変だからcsvファイルにしておく"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainデータの1回目の学習で予測したラベル0か1\n",
    "#今回は基本的にラベルではなく確率を使用\n",
    "\n",
    "# base_pre_train = pd.DataFrame( {'RandomForest': rfc_train.ravel(),\n",
    "#      'ExtraTrees': ext_train.ravel(),\n",
    "#      'AdaBoost': ada_train.ravel(),\n",
    "# #         'svm': svm_train.ravel(),\n",
    "#       'GradientBoost': gbct_train.ravel(),\n",
    "#          \"Logistic\":log_train.ravel(),\n",
    "#         \"lightGBM\":lgb_train.ravel(),\n",
    "#         \"XGBoost\":xgb_train.ravel()\n",
    "                            \n",
    "                                \n",
    "#     })\n",
    "# print('base_pre_train.shape : ', base_pre_train.shape)\n",
    "# base_pre_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1回目の学習でtrainデータのラベルを予測した時の口座開設確率\n",
    "base_pre_train_pro = pd.DataFrame( {'RandomForest': rfc_train_pro.ravel(),\n",
    "     'ExtraTrees': ext_train_pro.ravel(),\n",
    "     'AdaBoost': ada_train_pro.ravel(),\n",
    "#         'svm': svm_train.ravel(),\n",
    "      'GradientBoost': gbct_train_pro.ravel(),\n",
    "         \"Logistic\":log_train_pro.ravel(),\n",
    "        \"lightGBM\":lgb_train_pro.ravel(),\n",
    "        \"XGBoost\":xgb_train_pro.ravel()\n",
    "                            \n",
    "                                \n",
    "    })\n",
    "print('base_pre_train_pro.shape : ', base_pre_train_pro.shape)\n",
    "base_pre_train_pro.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1回目の学習でtestデータのラベルを予測した時の口座開設確率\n",
    "base_pre_test_pro = pd.DataFrame( {'RandomForest': rfc_test_pro.ravel(),\n",
    "     'ExtraTrees': ext_test_pro.ravel(),\n",
    "     'AdaBoost': ada_test_pro.ravel(),\n",
    "#         'svm': svm_train_pro.ravel(),\n",
    "      'GradientBoost': gbct_test_pro.ravel(),\n",
    "      \"Logistic\":log_test_pro.ravel(),\n",
    "        \"lightGBM\":lgb_test_pro.ravel(),\n",
    "        \"XGBoost\":xgb_test_pro.ravel()\n",
    "                                    \n",
    "    })\n",
    "print('base_pre_train.shape : ', base_pre_test_pro.shape)\n",
    "base_pre_test_pro.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testデータの1回目の学習で予測したラベル0か1\n",
    "\n",
    "# base_pre_test = pd.DataFrame( {'RandomForest': rfc_test.ravel(),\n",
    "#      'ExtraTrees': ext_test.ravel(),\n",
    "#      'AdaBoost': ada_test.ravel(),\n",
    "# #         'svm': svm_train_pro.ravel(),\n",
    "#       'GradientBoost': gbct_test.ravel(),\n",
    "#       \"Logistic\":log_test.ravel(),\n",
    "#         \"lightGBM\":lgb_test.ravel(),\n",
    "#         \"XGBoost\":xgb_test.ravel()\n",
    "                                    \n",
    "#     })\n",
    "# print('base_pre_test.shape : ', base_pre_test.shape)\n",
    "# base_pre_test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下で保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_pre_train_pro.to_csv(\"base_pre_train_pro2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_pre_train.to_csv(\"base_pre_train_pro2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_pre_test.to_csv(\"base_pre_test2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_pre_test_pro.to_csv(\"base_pre_test_pro2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2回目の学習を行うためのデータの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.concatenate((  rfc_train_pro,  gbct_train_pro,log_train_pro\n",
    "#                           svc_train_pro\n",
    "                          ,ada_train_pro,ext_train_pro,log_train_pro,lgb_train_pro,xgb_train_pro), axis=1)\n",
    "x_test = np.concatenate((  rfc_test_pro,  gbct_test_pro, log_test_pro\n",
    "#                           svc_test_pro\n",
    "                         ,ada_test_pro,ext_test_pro,log_test_pro, lgb_test_pro,xgb_test_pro\n",
    "                        ), axis=1)\n",
    "print('x_train.shape : ', x_train.shape)\n",
    "print('x_test.shape : ', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#こちらは０、1で予測したものを学習させるときのデータ\n",
    "\n",
    "# x_train1 = np.concatenate((  rfc_train,  gbct_train,log_train\n",
    "#                           svc_train,ada_train,ext_trainlog_train, lgb_train,xgb_train\n",
    "#                          ), axis=1)\n",
    "# x_test1 = np.concatenate((  rfc_test,  gbct_test,log_test \n",
    "#                           svc_test,ada_test,ext_test,log_test, lgb_test,xgb_test\n",
    "#                         ), axis=1)\n",
    "# print('x_train.shape : ', x_train1.shape)\n",
    "# print('x_test.shape : ', x_test1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2回目の学習RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_3=RandomForestClassifier(random_state=0, n_estimators=500)\n",
    "rfc_3.fit(x_train, y_train)\n",
    "predictions = rfc_3.predict(x_test)\n",
    "predictions_pro = rfc_3.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rfc_3=RandomForestClassifier(random_state=0, n_estimators=500)\n",
    "# rfc_3.fit(x_train1, y_train)\n",
    "# predictions1 = rfc_3.predict(x_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "テスト用のみ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_3.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_3.score(x_train1,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ロジスティック"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "X_std = scaler.transform(x_train)\n",
    "x_test_std=scaler.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(C=1.0)\n",
    "lr.fit(X_std, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "テスト用のみ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 正答率を出力\n",
    "print('train acc: %.3f' % lr.score(X_std, y_train))\n",
    "print('test acc: %.3f' % lr.score(x_test_std, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "xgb = xgb.XGBClassifier(learning_rate=0.1,max_depth=10)\n",
    "xgb.fit(x_train,y_train)\n",
    "pre_xgb = xgb.predict_proba(x_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "テスト用のみ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 正答率を出力\n",
    "print('train acc: %.3f' % xgb.score(x_train, y_train))\n",
    "print('test acc: %.3f' % xgb.score(x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "csvファイルにして保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predic_df=pd.DataFrame(predictions_pro)\n",
    "predic_df.to_csv(\"result_rf_new2_pro_log3.csv\")\n",
    "predic_log_pro=lr.predict_proba(x_test_std)\n",
    "predic_log_df=pd.DataFrame(predic_log_pro)\n",
    "pre_xgb=pd.DataFrame(pre_xgb)\n",
    "predic_log_df.to_csv(\"result_log_new2_pro_log3.csv\")\n",
    "pre_xgb.to_csv(\"result_xgb_pro.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
